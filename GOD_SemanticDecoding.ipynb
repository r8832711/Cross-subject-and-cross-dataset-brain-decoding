{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d0ae5c5-1736-4d8e-9621-c749180801a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "\n",
    "import os\n",
    "from os.path import join as opj\n",
    "from os.path import join, exists, split\n",
    "import time\n",
    "import urllib.request\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import zipfile\n",
    "import glob\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from nilearn import maskers\n",
    "from nilearn import plotting\n",
    "from GOD_decoding_utils import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import bdpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f281d6-08ed-45cf-bbae-d0cdb5fac183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1200, 2049),\n",
       " (1750, 2049),\n",
       " (50, 2049),\n",
       " (500, 2049),\n",
       " (50, 2049),\n",
       " (1200,),\n",
       " (1750,),\n",
       " (500,),\n",
       " 1200,\n",
       " 1750,\n",
       " 1200,\n",
       " 1750)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_data_path=\"/storage/GOD/GOD\"\n",
    "sub = \"Subject1\"\n",
    "roi = \"ROI_VC\"\n",
    "\n",
    "\n",
    "\n",
    "train_data_path=opj(base_data_path,f\"{sub}.h5\")\n",
    "\n",
    "# Initialize kamitani_data_mat with the path to a file containing data for Subject 3\n",
    "# kamitani_data_mat = f\"/data/fMRI/GOD/Subject{sub.split('_')[-1]}.h5\"\n",
    "kamitani_data_mat= f\"/storage/GOD/GOD/\"\n",
    "\n",
    "# Initialize imagenet_dir with the path to a directory containing images\n",
    "imagenet_dir = \"/storage/GOD/imagenet/images\"\n",
    "\n",
    "# Initialize test_img_csv and train_img_csv with the paths to two CSV files\n",
    "test_img_csv = '/storage/GOD/imagenet/images/image_test_id.csv'\n",
    "train_img_csv = '/storage/GOD/imagenet/images/image_training_id.csv'\n",
    "\n",
    "\n",
    "# Create a data_handler object using the specified arguments\n",
    "handler = data_handler(h5_file=train_data_path, test_img_csv=test_img_csv, train_img_csv=train_img_csv)\n",
    "\n",
    "\n",
    "# Get data using the get_data method of the handler object\n",
    "train, test, test_avg , train_imaginary,test_imaginary_avg = handler.get_data(normalize=1, roi=roi,imag_data=True)\n",
    "\n",
    "# Get labels using the get_labels method of the handler object\n",
    "labels_train, labels_test, labels_imaginary_test = handler.get_labels(imag_data=True)\n",
    "\n",
    "# Get filenames using the get_filenames method of the handler object\n",
    "filenames_train, filenames_test = handler.get_filenames()\n",
    "\n",
    "# Convert filenames_train and filenames_test from arrays to Python lists\n",
    "filenames_train = [i.item() for i in filenames_train]\n",
    "filenames_test = [i.item() for i in filenames_test]\n",
    "\n",
    "# Initialize img_dir_path with the path to a directory containing training images\n",
    "img_dir_path = \"/storage/GOD/imagenet/images/training\"\n",
    "\n",
    "# Initialize image_paths with a list of file paths to the training images\n",
    "image_paths = [os.path.join(img_dir_path, i) for i in filenames_train]\n",
    "\n",
    "# Initialize test_image_paths with a list of file paths to the test images\n",
    "test_image_paths = [os.path.join(imagenet_dir,\"test\", i) for i in filenames_test]\n",
    "\n",
    "# # Split the data into train and validation sets using the train_test_split function\n",
    "# fmri_train, fmri_val, image_train, image_val = train_test_split(Y, image_paths, test_size=0.1, random_state=42)\n",
    "\n",
    "train.shape, test.shape, test_avg.shape, train_imaginary.shape, test_imaginary_avg.shape, labels_train.shape, labels_test.shape, labels_imaginary_test.shape, len(filenames_train), len(filenames_test), len(image_paths), len(test_image_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59311b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_images = {}\n",
    "\n",
    "# Iterate over labels and store the first occurrence of each\n",
    "for label, path in zip(labels_test, test_image_paths):\n",
    "    if label not in unique_images:\n",
    "        unique_images[label] = path  # Store first occurrence only\n",
    "\n",
    "# Sort by label index (0 → 1 → 2)\n",
    "sorted_image_paths = [unique_images[i] for i in sorted(unique_images.keys())]\n",
    "\n",
    "print(sorted_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f13788c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Define image transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # Convert image to tensor\n",
    "])\n",
    "\n",
    "def load_images(image_paths):\n",
    "    tensors = []\n",
    "    for path in image_paths:\n",
    "        image = Image.open(path).convert(\"RGB\")  # Load image and convert to RGB\n",
    "        tensor = transform(image)  # Apply transformation\n",
    "        tensors.append(tensor)  # Append to list\n",
    "\n",
    "    # Stack tensors to maintain order\n",
    "    return torch.stack(tensors)\n",
    "\n",
    "\n",
    "train_images = load_images(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19807b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1200, 3, 500, 500])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5da0c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "train_sub1 = torch.from_numpy(test_avg)\n",
    "\n",
    "# Save the tensor to a file\n",
    "torch.save(train_sub1, 'GOD/subjectwise/test_brain_signals_VC_sub1.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
